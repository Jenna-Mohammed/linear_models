---
title: "Cross Validation"
author: "Jenna Mohammed"
date: '2023-11-14'
output: github_document
---

underfitting - we need stuff in our model to make it work 
overfitting  extra stuff just making noise

### implementing cross validation 

add_predictions() and add_residuals()
rmse()
crossv_msc()

```{r}
library(tidyverse)
library(modelr)
library(mgcv)
set.seed(1)
```

## Nonlinear data and CV 

```{r}
nonlin_df = 
  tibble(
    id = 1:100,
    x = runif(100, 0, 1),
    y = 1 - 10 * (x - .3) ^ 2 + rnorm(100, 0, .3)
  )
# what this dataset looks like 

nonlin_df |> 
  ggplot(aes(x = x, y = y)) + 
  geom_point()
```

 try to pick between different models that might work and see which has the best prediction accuracy 
 
 
 
- do the train/test split
 
```{r}
train_df = sample_n(nonlin_df, 80)

# ^ subject 8 is not included in this dataset 

test_df = anti_join(nonlin_df, train_df, by = "id")

# ^ subject 8 DOES show up

ggplot(train_df, aes(x = x, y = y)) + 
  geom_point() + 
  geom_point(data = test_df, color = "red")
```

```{r}
linear_mod = lm(y ~ x, data = train_df)

smooth_mod = mgcv::gam(y ~ s(x), data = train_df)
#^ gam function; give me a smooth function of x and use this to create the model

wiggly_mod = mgcv::gam(y ~ s(x, k = 30), sp = 10e-6, data = train_df)
```

quick visualization of the linear model 

```{r}
train_df |>
  modelr::add_predictions(linear_mod) |>
  ggplot(aes( x=x, y=y)) +
  geom_point() +
  geom_line(aes( y = pred))

#^ not a good fit, just a straight line through the data 

train_df |>
  modelr::add_predictions(smooth_mod) |>
  ggplot(aes( x=x, y=y)) +
  geom_point() +
  geom_line(aes( y = pred))

# ^ offers a smooth curve thrugh the data points; used he game function in above code chunk

train_df |>
  modelr::add_predictions(wiggly_mod) |>
  ggplot(aes( x=x, y=y)) +
  geom_point() +
  geom_line(aes( y = pred))
```

lowest residual standard deviation 

```{r}
rmse(linear_mod, train_df)
rmse(smooth_mod, train_df)
rmse(wiggly_mod, train_df)

rmse(linear_mod, test_df)
rmse(smooth_mod, test_df)
rmse(wiggly_mod, test_df)
```

^ RMSE on testing data gives a sense of out of sample prediction accuracy!

## Use modelr for 

```{r}
cv_df = 
  crossv_mc(nonlin_df, 100) 
```

apply each model to all training datasets and evaluate on all testing datasets

```{r}
cv_results = 
  cv_df |>
  mutate(
    linear_fit = map(train, \(df) lm(y ~ x, data = df))
  ) |>
  mutate(
    rmse_linear = map2(linear_fit, test, \(mod, df) rmse(mod, df))
  )
```

^whole linear mdoel function, take df as  input, plug it in, and return results in a linear model

```{r}
cv_df = 
  cv_df |> 
  mutate(
    linear_mod  = map(train, ~lm(armc ~ weight, data = .x)),
    pwl_mod     = map(train, ~lm(armc ~ weight + weight_cp, data = .x)),
    smooth_mod  = map(train, ~gam(armc ~ s(weight), data = as_tibble(.x)))) |> 
  mutate(
    rmse_linear = map2_dbl(linear_mod, test, ~rmse(model = .x, data = .y)),
    rmse_pwl    = map2_dbl(pwl_mod, test, ~rmse(model = .x, data = .y)),
    rmse_smooth = map2_dbl(smooth_mod, test, ~rmse(model = .x, data = .y)))
```
